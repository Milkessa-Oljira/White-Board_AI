{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2fd5f3",
   "metadata": {},
   "source": [
    "# WhiteboardEnv Technical Documentation & Explainer\n",
    "\n",
    "## Overview\n",
    "\n",
    "The **WhiteboardEnv** is an interactive Gymnasium environment designed for studying embodied sensorimotor learning and human-AI collaboration in a writing and/or drawing task. It simulates a whiteboard with realistic physics, featuring two controllable joints:\n",
    "\n",
    "- **Pen Joint:** Controls a pen that can draw (writing mode) or scroll the board (scrolling mode).\n",
    "- **Vision Joint:** Controls the focus window (a clear region) on a blurred board, shown as a red transparent tracker.\n",
    "\n",
    "The environment provides a composite image observation and a 4-dimensional numeric observation (reaction forces from the joints), while the action space is a hybrid of discrete selections and continuous forces.\n",
    "\n",
    "This document explains the environment’s key features, API, and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc4bb6",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "**Dual-Joint Control:**\n",
    "\n",
    "- **Pen Joint:** Can be in move, writing, or scrolling mode. In writing mode, isolated dots are drawn on the board. In scrolling mode, vertical scrolling is applied to the board.\n",
    "- **Vision Joint:** Controls a clear focus window over a blurred board. A red transparent square (with a border) indicates the focus area.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- The agent receives a composite image (as a Pygame Surface and a corresponding NumPy array) and a 4-dimensional vector of reaction forces (from the pen and vision joints, normalized by MAX_FORCE). The explicit positions of the joints are not provided.\n",
    "\n",
    "**Action Space:**\n",
    "\n",
    "- **joint_select:** `Discrete(2)` (0 for pen, 1 for vision).\n",
    "- **pen_mode:** `Discrete(3)` (0: move, 1: write, 2: scroll). Only used when controlling the pen.\n",
    "- **pen_force:** `Box(2,)` for continuous force on the pen joint.\n",
    "- **vision_force:** `Box(2,)` for continuous force on the vision joint.\n",
    "\n",
    "**Human Interaction:**\n",
    "\n",
    "- Human drawing: Blue dots are drawn when the mouse is used within the board.\n",
    "- Scrolling: The board can be scrolled vertically via human input (mouse wheel or key events) and via the AI’s scrolling mode.\n",
    "\n",
    "**Rendering:**\n",
    "\n",
    "- The board is rendered as a large Pygame Surface. A viewport is extracted (based on vertical offset) and displayed in a smaller window.\n",
    "- The AI pen is shown as a small black circle, and the focus window is indicated by a red transparent square with a border.\n",
    "\n",
    "**Physics Simulation:**\n",
    "\n",
    "- Uses Euler integration with mass and friction to update joint positions and velocities.\n",
    "- Scrolling incorporates extra friction and scales the applied force to adjust the board’s vertical offset.\n",
    "\n",
    "**Gymnasium API Compliance:**\n",
    "\n",
    "- Implements `reset()`, `step()`, and `close()`, with defined `observation_space` and `action_space`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298f2a8",
   "metadata": {},
   "source": [
    "## API Summary\n",
    "\n",
    "**Constructor:** `WhiteboardEnv(render_mode=\"human\")`\n",
    "- Initializes board dimensions, creates a Pygame Surface for the board, and sets up joint states and action/observation spaces.\n",
    "\n",
    "**reset()**\n",
    "- Resets the environment and returns `(observation, info)`, where the observation includes:\n",
    "  - `image_surface`: the composite image (Pygame Surface),\n",
    "  - `image_array`: the corresponding NumPy array,\n",
    "  - `numeric`: a 4D vector of reaction forces.\n",
    "\n",
    "**get_state()**\n",
    "- Returns the current observation.\n",
    "\n",
    "**step(action)**\n",
    "- Processes an action (provided as a dictionary) and updates joint states and board state.\n",
    "  - For pen control, uses `pen_mode` to determine behavior (move, write, or scroll).\n",
    "  - For vision control, applies the provided vision forces.\n",
    "- Returns `(observation, reward, terminated, truncated, info)`.\n",
    "\n",
    "**render()**\n",
    "- Extracts a viewport from the board based on a vertical offset and displays it using Pygame.\n",
    "  - Overlays indicators for the human pen, AI pen, and AI focus window.\n",
    "\n",
    "**close()**\n",
    "- Closes the Pygame display and cleans up resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4b450",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "Below is an example showing how to initialize and run the environment interactively.\n",
    "\n",
    "```python\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from whiteboard_env import WhiteboardEnv  # Ensure the environment is in this module\n",
    "\n",
    "# Initialize the environment\n",
    "env = WhiteboardEnv(render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Main interactive loop\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        # Additional event handling for human input goes here\n",
    "\n",
    "    # Sample a random action (or use your RL agent's policy)\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Render the environment\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "```\n",
    "\n",
    "This example demonstrates the basic workflow: reset, interact via step, render, and finally close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2a4e8",
   "metadata": {},
   "source": [
    "## Design Considerations\n",
    "\n",
    "- **Observation Design:**\n",
    "  - The agent does **not** receive explicit pen or vision positions. Instead, it must infer these from the composite image and reaction forces, encouraging more robust sensorimotor learning.\n",
    "\n",
    "- **Action Abstraction:**\n",
    "  - The hybrid action space combines discrete decisions (which joint to control, and for the pen, what mode to use) with continuous forces, reflecting the complexity of real-world motor control.\n",
    "\n",
    "- **Realistic Physics:**\n",
    "  - Joint updates incorporate mass, friction, and extra factors (for scrolling) to produce realistic movement.\n",
    "\n",
    "- **Human-AI Interaction:**\n",
    "  - The environment supports concurrent human drawing (via mouse) and AI control, enabling studies of collaboration or competition.\n",
    "\n",
    "- **Extensibility:**\n",
    "  - The modular design makes it easy to add more sophisticated reward signals, additional sensor modalities, or alternative control algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4bd5f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The **WhiteboardEnv** is a rich, interactive environment for studying sensorimotor learning and human-AI collaboration in a drawing task. Its realistic physics, hybrid action space, and multi-modal observations make it a valuable tool for reinforcement learning research.\n",
    "\n",
    "Feel free to explore, modify, and extend this environment to suit your experimental needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Usage\n",
    "import pygame\n",
    "from whiteboard_env import WhiteboardEnv  # Adjust the import path as needed\n",
    "\n",
    "env = WhiteboardEnv(render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # Here, you can replace the random action with your agent's policy\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Optionally, process reward or update your agent\n",
    "    if reward != 0:\n",
    "        print(\"Reward event:\", reward)\n",
    "\n",
    "    env.render()\n",
    "    pygame.time.Clock().tick(60)\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
